{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from tabulate import tabulate\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticker_information(ticker):\n",
    "    \n",
    "    headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36'}\n",
    "\n",
    "    ticker_information = requests.get(f\"https://efts.sec.gov/LATEST/search-index?keysTyped={ticker}\", headers=headers)\n",
    "\n",
    "    response = ticker_information.content.decode()#[\"hits\"][\"hits\"][0][\"_source\"][\"entity\"]\n",
    "    entity_name = json.loads(response)[\"hits\"][\"hits\"][0][\"_source\"][\"entity\"]\n",
    "    \n",
    "    return entity_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Consolidated_Schedule_Investments():\n",
    "    def __init__(self, ticker, entity_name, url):\n",
    "        self.ticker = ticker\n",
    "        self.entity_name = entity_name\n",
    "        self.url = url\n",
    "    \n",
    "    def save_File(self, data, filename):\n",
    "\n",
    "        with pd.ExcelWriter(filename) as writer:\n",
    "            for sheet_name, df in data:\n",
    "                df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        \n",
    "        # path = Path(filename)\n",
    "        # df = pd.DataFrame(data)\n",
    "        # df.to_csv(path, index=False)\n",
    "    \n",
    "    def get_table_of_url(self, driver):\n",
    "\n",
    "        urls = []\n",
    "        reporting_dates = []\n",
    "\n",
    "        table = driver.find_element(By.XPATH, '//*[@id=\"hits\"]/table')\n",
    "        rows = table.find_elements(By.TAG_NAME, 'tr')\n",
    "        \n",
    "        for i in range(1, len(rows)):\n",
    "            cell = driver.find_element(By.XPATH, f'//*[@id=\"hits\"]/table/tbody/tr[{i}]/td[1]/a')\n",
    "            data_adsh = cell.get_attribute('data-adsh')\n",
    "            data_adsh = data_adsh.replace('-','')\n",
    "            data_file_name = cell.get_attribute('data-file-name')\n",
    "            cell_reporting_date = driver.find_element(By.XPATH, f'//*[@id=\"hits\"]/table/tbody/tr[{i}]/td[3]').text\n",
    "            unformated_date = datetime.strptime(cell_reporting_date, \"%Y-%m-%d\")\n",
    "            reporting_dates.append(cell_reporting_date)\n",
    "\n",
    "            url = f\"https://www.sec.gov/Archives/edgar/data/{self.ticker}/{data_adsh}/{data_file_name}\"\n",
    "            urls.append(url)\n",
    "        \n",
    "        return urls, reporting_dates\n",
    "    \n",
    "    # Function to extract the target table based on specific heuristics\n",
    "    def extract_table_selenium(self, driver, n_rows, name_first_row):\n",
    "        \n",
    "        tables = driver.find_elements(By.TAG_NAME, \"table\")\n",
    "        candidate_tables = []\n",
    "\n",
    "        for table in tables:\n",
    "            # print(repr(table.text))\n",
    "            # Heuristics to identify the correct table\n",
    "            # Example: Select tables with more than 2 rows and 2 columns\n",
    "            rows = table.find_elements(By.TAG_NAME,'tr')\n",
    "            if len(rows) > n_rows:\n",
    "                i = 0\n",
    "                while True:\n",
    "                    if rows[i].text != '\\n\\n\\n\\n':\n",
    "                        cols = rows[i].find_elements(By.TAG_NAME, 'td')\n",
    "                        break\n",
    "\n",
    "                    i +=1\n",
    "                \n",
    "                if name_first_row in rows[0].text:\n",
    "                    candidate_tables.append(table.text)\n",
    "        \n",
    "        # If multiple tables match, refine selection logic\n",
    "        if len(candidate_tables) > 1:\n",
    "            # Example: Further refine based on specific row or column content\n",
    "            choices = [\"Principal Ammount\", \"Value\"]\n",
    "            for table in candidate_tables:\n",
    "                if any(x in str(table) for x in choices):\n",
    "                    continue\n",
    "                else:\n",
    "                    remove_idx = candidate_tables.index(table)\n",
    "                    candidate_tables.pop(remove_idx)\n",
    "            return candidate_tables  # Fallback to the first candidate\n",
    "\n",
    "        return None\n",
    "\n",
    "    \n",
    "    # Function to extract the target table based on specific heuristics\n",
    "    def extract_table(self, soup, n_rows, name_first_row):\n",
    "        tables = soup.find_all('table')\n",
    "        candidate_tables = []\n",
    "\n",
    "        for table in tables:\n",
    "            # print(repr(table.text))\n",
    "            # Heuristics to identify the correct table\n",
    "            # Example: Select tables with more than 2 rows and 2 columns\n",
    "            rows = table.find_all('tr')\n",
    "            if len(rows) > n_rows:\n",
    "                i = 0\n",
    "                while True:\n",
    "                    if rows[i].text != '\\n\\n\\n\\n':\n",
    "                        cols = rows[i].find_all(['td'])\n",
    "                        break\n",
    "\n",
    "                    i +=1\n",
    "                \n",
    "                if name_first_row in rows[1].text:\n",
    "                    candidate_tables.append(table)\n",
    "        \n",
    "        # If multiple tables match, refine selection logic\n",
    "        if len(candidate_tables) > 1:\n",
    "            # Example: Further refine based on specific row or column content\n",
    "            choices = [\"Co-Investments\", \"Primary Private Investment Funds\", \"Secondary Private Investment Funds\"]\n",
    "            for table in candidate_tables:\n",
    "                if any(x in str(table) for x in choices):\n",
    "                    continue\n",
    "                else:\n",
    "                    remove_idx = candidate_tables.index(table)\n",
    "                    candidate_tables.pop(remove_idx)\n",
    "            return candidate_tables  # Fallback to the first candidate\n",
    "\n",
    "        return None\n",
    "    \n",
    "    def amg_pantheon_fund(self):\n",
    "\n",
    "        dataframes = []\n",
    "\n",
    "        driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
    "        driver.implicitly_wait(5)\n",
    "        driver.maximize_window()\n",
    "        driver.get(self.url)\n",
    "        time.sleep(3)\n",
    "\n",
    "        \n",
    "\n",
    "        urls_dates = self.get_table_of_url(driver)\n",
    "        dates = urls_dates[1]\n",
    "        urls = urls_dates[0]\n",
    "        headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36'}\n",
    "        \n",
    "        for j in range(len(urls)):\n",
    "            while True:\n",
    "                r = requests.get(urls[j], headers=headers)\n",
    "                if r.status_code == 200:\n",
    "                    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "                    break\n",
    "\n",
    "            target_table = self.extract_table(soup, 10, \"Initial\")\n",
    "            firts_text = False\n",
    "            full_text_table = \"\"\n",
    "\n",
    "            for table in target_table:\n",
    "                if target_table:\n",
    "                    texts = table.text\n",
    "                    texts = texts.replace('\\xa0', '')\n",
    "                    texts = texts.replace('\\u2003', '')\n",
    "                    texts = texts.strip('\\n\\t ')\n",
    "                    texts = texts.replace('\\n \\n', '\\n\\n')\n",
    "                    texts = texts.replace('Initial\\nAcquisition', 'Security\\tInitial Acquisition')\n",
    "                    texts = texts.replace('Initial Acquisition\\nDate', 'Security\\tInitial Acquisition Date')\n",
    "                    texts = texts.replace('InitialAcquisitionDate', 'Security\\tInitial Acquisition Date')\n",
    "                    texts = texts.replace('PercentofNet\\nAssets', 'Percent of Net Assets')\n",
    "                    texts = re.sub(r'(?<=\\w)(\\n)+Secondary', ' \\nSecondary',texts)\n",
    "                    texts = texts.replace(' (continued)', '')\n",
    "                    texts = texts.replace('\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', '\\t\\t\\t\\t\\n')\n",
    "                    texts = texts.replace('\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', '\\n')\n",
    "                    texts = re.sub(r'(?<=%)\\n+(?=\\$)', '\\t', texts)\n",
    "                    texts = texts.replace('\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', '\\t\\t')\n",
    "                    texts = texts.replace('\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', '\\t\\t\\t\\t\\n')\n",
    "                    texts = texts.replace('\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', '\\t\\t')\n",
    "                    texts = texts.replace('\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', '\\t\\t\\t\\t\\n')\n",
    "                    texts = re.sub(r'(?<=[a-zA-Z])\\n+(?=[0-9])', '\\t', texts)\n",
    "                    texts = re.sub(r'Net Assets\\n+', 'Net Assets\\t\\t', texts)\n",
    "                    texts = re.sub(r'Other Assets, less Liabilities\\n+', 'Other Assets, less Liabilities\\t\\t', texts)\n",
    "                    texts = texts.replace('\\n\\n\\n\\n\\n\\n\\n\\n\\n', ' \\n')\n",
    "                    texts = texts.replace('\\n\\n\\n\\n\\n\\n\\n\\n', '\\n')\n",
    "                    texts = re.sub(r'\\n+(?=\\d)', '\\t', texts)\n",
    "                    texts = re.sub(r'(?<=\\S)\\s*\\n{7}(?=\\s*\\d)', '\\t', texts)\n",
    "                    texts = texts.replace('\\n\\n\\n\\n\\n\\n\\n', '\\n')\n",
    "                    texts = texts.replace('\\n\\n\\n\\n\\n\\n', '\\n')\n",
    "                    texts = texts.replace('\\n\\n\\n\\n', '\\t')\n",
    "                    texts = texts.replace(\"\\n\\n\\n Net Assets\", \"\\n Net Assets\")\n",
    "                    texts = texts.replace(\"\\n\\n Net Assets\", \"\\n Net Assets\")\n",
    "                    texts = texts.replace('\\n\\n\\n', '\\t')\n",
    "                    texts = texts.replace('\\n\\nSe', '\\n')\n",
    "                    texts = texts.replace('\\n\\n', '\\t')\n",
    "                    texts = re.sub(r'\\n%', '%', texts)\n",
    "                    texts = re.sub(r'(\\S)\\n(\\S)', r'\\1 \\2', texts)\n",
    "                    texts = re.sub(r'(\\S)\\n(\\s*\\()', r'\\1 \\2', texts)\n",
    "                    texts = re.sub(r'(?<=\\S)\\n(?=\\d)|(?<=\\d)\\n(?=\\S)', '', texts)\n",
    "                    texts = re.sub(r'^[ \\t]+(?=\\S)', '', texts, flags=re.MULTILINE)\n",
    "                    texts = re.sub(r'\\t{5,} ?', '\\n', texts)\n",
    "                    texts = re.sub(r'(?<=\\d)\\t{3,}', '\\n', texts)\n",
    "                    texts = texts.replace('\\t Total', '\\n Total')\n",
    "                    texts = texts.replace('$', '')\n",
    "                    texts = re.sub(r'(\\(\\w\\),)+\\*', '', texts)\n",
    "                    texts = texts.replace('*', '')\n",
    "                    texts = texts.replace('\\t\\t', '\\t')\n",
    "                    texts = texts.replace(\"\\t\\t\\n\", \"\\n\")\n",
    "                    texts = re.sub(r'(?<=\\d)\\t\\n', '\\n', texts)\n",
    "\n",
    "                    if firts_text:\n",
    "                        full_text_table += f\"\\n{texts}\"\n",
    "                    else:\n",
    "                        firts_text= True\n",
    "                        full_text_table = texts\n",
    "\n",
    "\n",
    "                    # print(repr(f\"\\n----------------------------------------------------------------------------------\\n{texts}\"))\n",
    "                    # print(f\"\\n----------------------------------------------------------------------------------\\n{texts}\")\n",
    "            # print(full_text_table)\n",
    "            result = StringIO(full_text_table)\n",
    "            try:\n",
    "                df = pd.read_csv(result, sep='\\t', header=0, index_col=False)\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            if len(df.columns) > 4:\n",
    "                df.columns = [\"Security\", \"Initial Acquisition Date\", \"Shares\", \"Value\", \"Percent of Net Assets\"]\n",
    "                df = df[(df.Security != \"Security\")&(df[\"Initial Acquisition Date\"] != \"Initial Acquisition Date\")&(df.Shares != \"Shares\")&(df.Value != \"Value\")&(df[\"Percent of Net Assets\"] != \"Percent of Net Assets (1)\")]\n",
    "            else:\n",
    "                df.columns = [\"Security\", \"Initial Acquisition Date\", \"Shares\", \"Value\"]\n",
    "                df = df[(df.Security != \"Security\")&(df[\"Initial Acquisition Date\"] != \"Initial Acquisition Date\")&(df.Shares != \"Shares\")&(df.Value != \"Value\")]\n",
    "            \n",
    "            \n",
    "            df[\"Report Date\"] = [dates[j] for i in range(len(df['Initial Acquisition Date'].values))]\n",
    "\n",
    "            # Create a new column for sections\n",
    "            df['Type'] = np.nan\n",
    "\n",
    "            # Forward fill the section column for non-NaN 'Security' rows\n",
    "            section = None\n",
    "            for i, row in df.iterrows():\n",
    "                try:\n",
    "                    if pd.isna(row['Initial Acquisition Date']) and pd.isna(row['Shares']) and pd.isna(row['Value']) and pd.isna(row['Percent of Net Assets']):\n",
    "                        section = row['Security']\n",
    "                except KeyError:\n",
    "                    if pd.isna(row['Initial Acquisition Date']) and pd.isna(row['Shares']) and pd.isna(row['Value']):\n",
    "                        section = row['Security']\n",
    "                \n",
    "                df.at[i, 'Type'] = section\n",
    "\n",
    "            try:\n",
    "                # Drop the rows that are sections\n",
    "                df = df.dropna(subset=['Initial Acquisition Date', 'Shares', 'Value', 'Percent of Net Assets'])\n",
    "            except KeyError:\n",
    "                # Drop the rows that are sections\n",
    "                df = df.dropna(subset=['Initial Acquisition Date', 'Shares', 'Value'])\n",
    "\n",
    "            # Reset the index of the DataFrame\n",
    "            df = df.reset_index(drop=True)\n",
    "\n",
    "            df['Value'] = df['Value'].str.replace(',', '')\n",
    "\n",
    "            # Define the pattern to search for (partial match)\n",
    "            pattern = re.compile(r'^Investment is issued in a private placement offering')\n",
    "            original_price_text = soup.find(lambda tag: tag.name == \"p\" and pattern.search(tag.text)).text\n",
    "\n",
    "            # Regular expression pattern to match numbers with commas\n",
    "            pattern = r'\\$\\d{1,3}(?:,\\d{3})*'\n",
    "            # Find all matches in the text\n",
    "            matches = re.findall(pattern, original_price_text)\n",
    "            if matches:\n",
    "                matches = matches[:-1]\n",
    "                matches = [x.replace('$', '').replace(',', '') for x in matches]\n",
    "            \n",
    "            else:\n",
    "                date = df['Report Date'][0]\n",
    "                date_obt = datetime.strptime(date, \"%Y-%m-%d\")\n",
    "\n",
    "                pattern = re.compile(r'^\\s*As of {0}\\xa0{1}, {2}, the aggregate cost'.format(date_obt.strftime(\"%B\"), date_obt.strftime(\"%d\"), date_obt.strftime(\"%Y\")))\n",
    "                soup = BeautifulSoup(r.text, 'html.parser')\n",
    "                \n",
    "                original_price_text = soup.find(lambda tag: tag.name == \"td\" and pattern.search(tag.text))\n",
    "                if original_price_text == None:\n",
    "                    pattern = re.compile(r'^\\n*\\s*As of {0}\\xa0{1}, {2}, the aggregate cost'.format(date_obt.strftime(\"%B\"), date_obt.strftime(\"%d\"), date_obt.strftime(\"%Y\")))\n",
    "                    driver.get(urls[4])\n",
    "                    text_tag = driver.find_element(By.TAG_NAME, 'text')\n",
    "                    p_tags = text_tag.find_elements(By.TAG_NAME, 'p')\n",
    "                    \n",
    "                    for paragraph in p_tags:\n",
    "                        pattern = re.compile(r'^\\n*\\s*As of {0} {1}, {2}, the aggregate cost'.format(date_obt.strftime(\"%B\"), date_obt.strftime(\"%d\"), date_obt.strftime(\"%Y\")))\n",
    "                        result = pattern.search(paragraph.text)\n",
    "                        if result:\n",
    "                            original_price_text = paragraph.text\n",
    "                            break\n",
    "                else:\n",
    "                    original_price_text = original_price_text.text\n",
    "                # Regular expression pattern to match numbers with commas\n",
    "                pattern = r'\\$\\d{1,3}(?:,\\d{3})*'\n",
    "                # Find all matches in the text\n",
    "                matches = re.findall(pattern, original_price_text)\n",
    "                matches = matches[:-1]\n",
    "                matches = [x.replace('$', '').replace(',', '') for x in matches]\n",
    "\n",
    "            df['Original Value'] = matches\n",
    "\n",
    "            try:\n",
    "                columns = [\"Type\", \"Security\", \"Initial Acquisition Date\", \"Report Date\", \"Shares\", \"Original Value\", \"Value\", \"Percent of Net Assets\"]\n",
    "                df = df[columns]\n",
    "            except KeyError:\n",
    "                columns = [\"Type\", \"Security\", \"Initial Acquisition Date\", \"Report Date\", \"Shares\", \"Original Value\", \"Value\"]\n",
    "                df = df[columns]\n",
    "            \n",
    "            df_obj = df.select_dtypes('object')\n",
    "\n",
    "            df[df_obj.columns] = df_obj.apply(lambda x: x.str.strip())\n",
    "\n",
    "            df['Report Date'] = pd.to_datetime(df['Report Date'], format=\"%Y-%m-%d\")\n",
    "            df['Report Date'] = df['Report Date'].apply(lambda x: x.strftime('%m/%d/%Y'))\n",
    "            df['Initial Acquisition Date'] = pd.to_datetime(df['Initial Acquisition Date'], format='%m/%d/%Y')\n",
    "            df['Initial Acquisition Date'] = df['Initial Acquisition Date'].apply(lambda x: x.strftime('%m/%d/%Y'))\n",
    "\n",
    "            date = datetime.strptime(df['Report Date'][0], '%m/%d/%Y')\n",
    "            date = date.strftime('%Y_%m_%d')\n",
    "            print(date)\n",
    "\n",
    "            # dataframes.append((f'{date}', df))\n",
    "        \n",
    "        \n",
    "            \n",
    "            df.to_excel(f\"Private Credit Funds.xlsx\", sheet_name=f\"{date}\", index=False)\n",
    "    \n",
    "    def first_trust_private_fund(self):\n",
    "        \n",
    "        dataframes = []\n",
    "\n",
    "        chrome_install = ChromeDriverManager().install()\n",
    "\n",
    "        folder = os.path.dirname(chrome_install)\n",
    "        chromedriver_path = os.path.join(folder, \"chromedriver.exe\")\n",
    "\n",
    "\n",
    "        driver = webdriver.Chrome(service=ChromeService(chromedriver_path))\n",
    "        driver.implicitly_wait(5)\n",
    "        driver.maximize_window()\n",
    "        driver.get(self.url)\n",
    "        time.sleep(3)\n",
    "\n",
    "        \n",
    "\n",
    "        urls_dates = self.get_table_of_url(driver)\n",
    "        dates = urls_dates[1]\n",
    "        urls = urls_dates[0]\n",
    "        print(urls[0])\n",
    "        headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36'}\n",
    "\n",
    "        # for j in range(len(urls)):\n",
    "        driver.get(urls[2])\n",
    "\n",
    "        target_table = self.extract_table_selenium(driver, 7, \"Principal\")\n",
    "        # print(target_table[0])\n",
    "        firts_text = False\n",
    "        full_text_table = \"\"\n",
    "        df = None\n",
    "        first = True\n",
    "\n",
    "        # Current section tracker\n",
    "        current_section = \"\"\n",
    "\n",
    "        for table in target_table:\n",
    "            if target_table:\n",
    "                texts = table\n",
    "                texts = texts.replace('\\u2007', '')\n",
    "                texts = texts.replace('\\u2009', '')\n",
    "                texts = texts.replace('Principal\\nAmount1', 'Principal Amount')\n",
    "                texts = texts.replace('Principal\\nAmount', 'Principal Amount')\n",
    "                texts = texts.replace('Principal Amount           Value', 'Principal Amount\\nValue')\n",
    "                texts = texts.replace(' Palmer', '\\nPalmer')\n",
    "                texts = texts.replace('Inc.9', 'Inc.')\n",
    "                texts = texts.replace('\\npoints', ' points')\n",
    "                texts = texts.replace('\\nbasis', ' basis')\n",
    "                texts = texts.replace('basis\\n', 'basis ')\n",
    "                texts = texts.replace('Ares Capital 2023-1', 'Ares Capital')\n",
    "                texts = texts.replace('Trust 2021-1', 'Trust')\n",
    "                texts = texts.replace('8 Stronghold Digital Mining, Inc.–Class A*,1 35', '8\\nStronghold Digital Mining, Inc.–Class A')\n",
    "                texts = texts.replace('),\\n', '), ')\n",
    "\n",
    "                # Split the data into lines\n",
    "                lines = texts.split('\\n')\n",
    "                lines.pop(0)\n",
    "                lines.pop(0)\n",
    "\n",
    "                # Initialize lists for each column\n",
    "                principal_amount = []\n",
    "                value = []\n",
    "                security = []\n",
    "                company = []\n",
    "                type = []\n",
    "                \n",
    "                f_value = False\n",
    "                \n",
    "                # Process each line\n",
    "                for i in range(0, len(lines)):\n",
    "                    \n",
    "                    variable = lines[i]\n",
    "                    variable_no = lines[i-1]\n",
    "\n",
    "                    if 'ASSET' in lines[i] or 'BANK LOANS' in lines[i] or \"CLOSED-END\" in lines[i] or \"COLLATERALIZED LOAN\" in lines[i] or \"ELECTRIC-GENERATION\" in lines[i]:\n",
    "                        if \"Continued\" not in lines[i] and \"TOTAL\" not in lines[i]:\n",
    "                            current_section = lines[i].strip()\n",
    "\n",
    "                        continue\n",
    "\n",
    "                    is_value = re.findall(r'\\d{1,3}(?:,\\d{3})+', lines[i])\n",
    "                    is_company = re.findall(r'\\b(?!\\d+|.*\\d+)[A-Za-z/&.,\\s]+\\b(?<![\\d/])', lines[i])\n",
    "                    is_security =  re.findall(r'.*?\\d{1,2}\\.\\d{1,3}%.*?\\d{1,2}\\/\\d{1,2}\\/\\d{4}', lines[i])\n",
    "\n",
    "                    # print(f\"{len(is_value) == 1} {\"TOTAL\" not in lines[i-1]} {\"TOTAL\" not in lines[i-2]}\")\n",
    "\n",
    "                    if is_value and len(is_value) == 1 and \"TOTAL\" not in lines[i-1] and (i < 2 or \"TOTAL\" not in lines[i-2]):\n",
    "                        \n",
    "                        if \"ELECTRIC-GENERATION\" in current_section:\n",
    "                            break\n",
    "\n",
    "                        is_company_alt = re.sub(r\"\\d{1,3}(?:,\\d{3})+\", \"\", lines[i]).strip()\n",
    "                        if is_company_alt != '' and is_company_alt != '$':\n",
    "                            if '$' in is_company_alt:\n",
    "                                lines[i] = lines[i].replace('$', '').strip()\n",
    "                            \n",
    "                            company.append(is_company_alt)\n",
    "\n",
    "                        if len(is_value) == 1 and is_security:\n",
    "                            security.append(is_security[0].strip())\n",
    "\n",
    "                        if not f_value:\n",
    "                            f_value = True\n",
    "                            principal_amount.append(is_value[0].strip())\n",
    "\n",
    "                        elif f_value:\n",
    "                            f_value = False\n",
    "\n",
    "                            value.append(is_value[0].strip())\n",
    "                            if current_section != \"\":\n",
    "                                type.append(current_section)\n",
    "                    \n",
    "                    elif is_value and len(is_value) == 2 and \"TOTAL\" not in lines[i-1] and (i < 2 or \"TOTAL\" not in lines[i-2]):\n",
    "                        f_value = False\n",
    "\n",
    "                        principal_amount.append(is_value[0].strip())\n",
    "                        value.append(is_value[1].strip())\n",
    "\n",
    "                        is_security =  re.findall(r'\\d{1,2}\\.\\d{1,3}%.*?\\d{1,2}\\/\\d{1,2}\\/\\d{4}', lines[i])\n",
    "                        \n",
    "                        security.append(is_security[0].strip())\n",
    "\n",
    "                        is_company = re.findall(r'\\b(?!\\d+|.*\\d+)[A-Za-z/&.,\\s]+\\b(?<![\\d/])', lines[i-1])\n",
    "\n",
    "                        if not is_company:\n",
    "                            company.append(company[-1])\n",
    "                        \n",
    "                        if current_section != \"\":\n",
    "                            type.append(current_section)\n",
    "\n",
    "                    elif is_security:\n",
    "                        \n",
    "                        if \"ELECTRIC-GENERATION\" in current_section:\n",
    "                            break\n",
    "\n",
    "                        if \"CLOSED-END\" in current_section:\n",
    "                            security.append('')\n",
    "                            continue\n",
    "                        security.append(is_security[0].strip())\n",
    "                        \n",
    "                        is_company = re.findall(r'\\b(?!\\d+|.*\\d+)[A-Za-z/&.,\\s]+\\b(?<![\\d/])', lines[i-1])\n",
    "\n",
    "                        if \"Series\" in lines[i] and not is_company:\n",
    "                            try:\n",
    "                                company.append(company[-1])\n",
    "                            except IndexError:\n",
    "                                company.append(df[\"Company\"].iloc[-1])\n",
    "                    \n",
    "                    elif is_company and 'Number' not in lines[i] and 'of Shares' not in lines[i] and 'Principal' not in lines[i]:\n",
    "\n",
    "                        if \"ELECTRIC-GENERATION\" in current_section:\n",
    "                            break\n",
    "                        \n",
    "                        company.append(lines[i].strip())\n",
    "\n",
    "                        if \"CLOSED-END\" in current_section:\n",
    "                            security.append('')\n",
    "                \n",
    "                print(len(principal_amount))\n",
    "                print(len(value))\n",
    "                print(len(security))\n",
    "                print(len(company))\n",
    "                print(len(type))\n",
    "\n",
    "                print(principal_amount)\n",
    "                print(value)\n",
    "                print(security)\n",
    "                print(company)\n",
    "                print(type)\n",
    "\n",
    "                if first:\n",
    "                    # Create a DataFrame\n",
    "                    df = pd.DataFrame({\n",
    "                        'Principal Amount': principal_amount,\n",
    "                        'Value': value,\n",
    "                        'Security': security,\n",
    "                        'Company': company,\n",
    "                        'Type': type\n",
    "                    })\n",
    "                    first = False\n",
    "                else:\n",
    "                    # Create a DataFrame\n",
    "                    df_new = pd.DataFrame({\n",
    "                        'Principal Amount': principal_amount,\n",
    "                        'Value': value,\n",
    "                        'Security': security,\n",
    "                        'Company': company,\n",
    "                        'Type': type\n",
    "                    })\n",
    "                    df = pd.concat([df, df_new], ignore_index=True)\n",
    "        \n",
    "        df['Value'] = df['Value'].str.replace(',', '')\n",
    "        df['Value'] = df['Value'].astype('int32')\n",
    "        df['Principal Amount'] = df['Principal Amount'].str.replace(',', '')\n",
    "        df['Principal Amount'] = df['Principal Amount'].astype('int32')\n",
    "\n",
    "        df[\"Report Date\"] = [dates[2] for i in range(len(df['Principal Amount'].values))]\n",
    "        df['Report Date'] = pd.to_datetime(df['Report Date'], format=\"%Y-%m-%d\")\n",
    "        df['Report Date'] = df['Report Date'].apply(lambda x: x.strftime('%m/%d/%Y'))\n",
    "\n",
    "        date = datetime.strptime(df['Report Date'][0], '%m/%d/%Y')\n",
    "        date = date.strftime('%Y_%m_%d')\n",
    "\n",
    "        print(df)\n",
    "        df.to_excel(f\"Private Credit Funds.xlsx\", sheet_name=f\"{date}\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/Archives/edgar/data/1912963/000110465924069571/tm2413894d1_ncsr.htm\n"
     ]
    }
   ],
   "source": [
    "ticker = 1912963\n",
    "entity = get_ticker_information(ticker)\n",
    "url = f\"https://www.sec.gov/edgar/search/#/category=custom&ciks=000{ticker}&entityName={entity}(CIK 000{ticker})&forms=N-CSR,N-CSRS\"\n",
    "# print(url)\n",
    "\n",
    "\n",
    "# Consolidated_Schedule_Investments(ticker, entity, url).amg_pantheon_fund()\n",
    "Consolidated_Schedule_Investments(ticker, entity, url).first_trust_private_fund()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "solve",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
